---


---

<h1 id="querying-with-the-aws-cli-guide-w-examples">Querying with the AWS-CLI, Guide w/ Examples</h1>
<h3 id="managing-logistics-and-configuration">Managing Logistics and Configuration</h3>
<h5 id="aws-cli-output">AWS CLI Output</h5>
<p>Official AWS Documentation<br>
<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html</a></p>
<p>Controlling command output from the AWS CLI; options include JSON, YAML, text, and table<br>
<a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html</a></p>
<ul>
<li>default output is JSON</li>
<li>YAML is only available when using AWS-CLI-v2</li>
</ul>
<p>Environment Variable ‘AWS_DEFAULT_OUTPUT’ can be set in order to avoid including the --output flag with each command</p>
<ul>
<li>export AWS_DEFAULT_OUTPUT=“text”</li>
</ul>
<h5 id="command-line-jsonyaml--processor">Command Line JSON/YAML  processor</h5>
<p>‘jq’ is an industry-standard JSON processor intended for use on the CLI to formulate advanced queries; instructions on downloading, as well as official tutorials, can be found at<br>
<a href="http://stedolan.github.io/jq/">http://stedolan.github.io/jq/</a></p>
<p>‘yq’ is extremely similar to ‘jq’ except it is for use with YAML. Download and Usage instructions can be found at<br>
<a href="http://mikefarah.github.io/yq/">http://mikefarah.github.io/yq/</a></p>
<h5 id="output-using-text-format">Output using ‘Text’ format</h5>
<p>The text format organizes the AWS CLI output into tab-delimited lines. It works well with traditional Unix text tools such as grep, sed, and awk, and the text processing performed by PowerShell.</p>
<ul>
<li>From AWS “We strongly recommend that if you specify text output, you also always use the --query option to ensure consistent behavior.”</li>
</ul>
<h5 id="output-using-table-format">Output using ‘Table’ format</h5>
<p>The <code>table</code> format produces human-readable representations of complex AWS CLI output in a tabular form.</p>
<h5 id="deciphering-return-codes-from-the-cli">Deciphering Return Codes from the CLI</h5>
<h6 id="httpsdocs.aws.amazon.comclilatestuserguidecli-usage-returncodes.html"><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-returncodes.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-returncodes.html</a></h6>
<p>|0|  The command completed successfully. There were no errors generated by either the AWS CLI or by the AWS service to which the request was sent.|<br>
|1|One or more Amazon S3 transfer operations failed.  <em>Limited to S3 commands.</em><br>
|2| The meaning of this return code depends on the command:</p>
<ul>
<li>
<p><em>Applicable to all CLI commands</em></p>
</li>
<li>
<p><em>Limited to S3 commands</em><br>
|130| The command was interrupted by a SIGINT (Ctrl+C).<br>
|255| The command failed. There were errors generated by the AWS CLI or by the AWS service to which the request was sent.</p>
</li>
</ul>
<h2 id="what-are-all-the-options-available-for-use-with-the-aws-cli">What are all the options available for use with the AWS-CLI?</h2>
<h4 id="to-include-fewer-items-at-a-time-in-the-aws-cli-output-use-the---max-items-option">To include fewer items at a time in the AWS CLI output, use the <code>--max-items</code> option</h4>
<pre><code>aws s3api list-objects \ --bucket my-bucket \ --max-items 100
</code></pre>
<h4 id="you-can-use-the---page-size-option-to-specify-that-the-aws-cli-request-a-smaller-number-of-items-from-each-call-to-the-aws-service.">You can use the <code>--page-size</code> option to specify that the AWS CLI request a smaller number of items from each call to the AWS service.</h4>
<pre><code>aws s3api list-objects \ --bucket my-bucket \ `--page-size 100`
</code></pre>
<h4 id="use-the---starting-tokenoption-if-the-number-of-items-output---max-items-is-fewer-than-the-total-number-of-items-returned-by-the-underlying-api-calls-the-output-includes-a-nexttoken-that-you-can-pass-to-a-subsequent-command-to-retrieve-the-next-set-of-items.">Use the <code>--starting-token</code>option if the number of items output (–max-items) is fewer than the total number of items returned by the underlying API calls; the output includes a NextToken that you can pass to a subsequent command to retrieve the next set of items.</h4>
<p><code>aws s3api list-objects \ --bucket my-bucket \ --max-items 100 \ `--starting-token eyJNYXJrZXIiOiBudWxsLCAiYm90b190cnVuY2F0ZV9hbW91bnQiOiAxfQ==`</code></p>
<p>For more details about a failure, run the command with the <code>--debug</code> switch. This produces a detailed report of the steps the AWS CLI uses to process the command, and what the result of each step was.</p>
<h4 id="use-the---generate-cli-skeleton-option-to-generate-the-template-with-the-correct-parameter-names-to-avoid-errors.-you-can-also-reference-the-api-reference-guide-for-the-service-to-see-the-expected-parameter-names.-you-can-delete-any-parameters-from-the-template-that-are-not-required-and-for-which-you-dont-want-to-supply-a-value.">Use the <code>--generate-cli-skeleton</code> option to generate the template with the “correct” parameter names to avoid errors. You can also reference the API Reference Guide for the service to see the expected parameter names. You can delete any parameters from the template that are not required and for which you don’t want to supply a value.</h4>
<pre><code> aws ec2 run-instances --generate-cli-skeleton
</code></pre>
<h5 id="to-generate-and-use-a-parameter-skeleton-file">To generate and use a parameter skeleton file</h5>
<ol>
<li>
<p>Run the command with the --generate-cli-skeleton parameter to produce either JSON or YAML and direct the output to a file to save it.</p>
<p>aws ec2 run-instances --generate-cli-skeleton input&gt; ec2runinst.json</p>
</li>
<li>
<p>Open the parameter skeleton file in your text editor and remove any of the parameters that you don’t need. For example, you might strip the template down to the following. Be sure that the file is still valid JSON or YAML after you remove the elements you don’t need.</p>
</li>
</ol>
<p>In this example, we leave the <code>DryRun</code> parameter set to <code>true</code> to use the Amazon EC2 dry run feature. This feature lets you safely test the command without actually creating or modifying any resources.</p>
<pre><code>{
"DryRun": true,
"ImageId": "",
"KeyName": "",
"SecurityGroups": [
    ""
],
"InstanceType": "",
"Monitoring": {
    "Enabled": true
}
}
</code></pre>
<ol start="3">
<li>
<p>Fill in the remaining values with values appropriate for your scenario. In this example, we provide the instance type, key name, security group, and identifier of the Amazon Machine Image (AMI) to use. This example assumes the default AWS Region. The AMI ami-dfc39aef is a 64-bit Amazon Linux image hosted in the us-west-2 Region. If you use a different Region, you must find the correct AMI ID to use.</p>
<p>{<br>
“DryRun”: true,<br>
“ImageId”: “ami-dfc39aef”,<br>
“KeyName”: “mykey”,<br>
“SecurityGroups”: [<br>
“my-sg”<br>
],<br>
“InstanceType”: “t2.micro”,<br>
“Monitoring”: {<br>
“Enabled”: true<br>
}<br>
}</p>
</li>
<li>
<p>Run the command with the completed parameters by passing the completed template file to either the --cli-input-json or --cli-input-yaml parameter by using the file:// prefix. The AWS CLI interprets the path to be relative to your current working directory, so in the following example that displays only the file name with no path, it looks for the file directly in the current working directory.</p>
</li>
</ol>
<p>The dry run error indicates that the JSON or YAML is formed correctly and that the parameter values are valid. If other issues are reported in the output, fix them and repeat the previous step until the “Request would have succeeded” message is displayed.</p>
<pre><code>aws ec2 run-instances --cli-input-json file://ec2runinst.json
</code></pre>
<ol start="5">
<li>
<p>Now you can set the  <code>DryRun</code>  parameter to  <code>false</code>  to disable dry run.</p>
<p>{<br>
“DryRun”: false,<br>
“ImageId”: “ami-dfc39aef”,<br>
“KeyName”: “mykey”,<br>
“SecurityGroups”: [<br>
“my-sg”<br>
],<br>
“InstanceType”: “t2.micro”,<br>
“Monitoring”: {<br>
“Enabled”: true<br>
}<br>
}</p>
</li>
<li>
<p>Run the command, and run-instances actually launches an EC2 instance and displays the details generated by the successful launch. The format of the output is controlled by the --output parameter, separately from the format of your input parameter template.</p>
<p>aws ec2 run-instances --cli-input-json file://ec2runinst.json --output json</p>
</li>
</ol>
<h3 id="how-to-filter-the-output-with-the----query--option">How to filter the output with the  <code>--query</code>  option</h3>
<p>The AWS CLI provides built-in JSON-based output filtering capabilities with the --query option. The --query parameter accepts strings that are compliant with the JMESPath specification (<a href="http://jmespath.org/">http://jmespath.org/</a>)</p>
<p>Things to Consider:</p>
<ul>
<li>With ‘–output text’ the command response is paginated before the ‘–query’ filter is applied; AWS-CLI runs the query once per page</li>
</ul>
<h2 id="aws-cli-query-examples">AWS CLI Query Examples</h2>
<h3 id="official-aws-documentation">Official AWS Documentation</h3>
<h6 id="these-examples-are-taken-from-httpsdocs.aws.amazon.comclilatestuserguidecli-usage-output.html-and-serve-as-solid-resources-for-establishing-bedrock-knowledge-of-the-querying-ability-with-aws-cli">These examples are taken from <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html">https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-output.html</a> and serve as solid resources for establishing bedrock knowledge of the querying ability with AWS-CLI</h6>
<p><strong>Display only the first volume from the list of volumes returned by the describe-volumes command</strong></p>
<pre><code>aws ec2 describe-volumes --query 'Volumes[0]'
</code></pre>
<p><strong>Show three elements from each volume associated with an instance</strong> (i.e VolumeId, AvailabilityZone, Size); this example uses the wildcard notation to iterate over the volumes; dictionaries are unordered, which is something to keep in mind; documentation on the wildcard notation can be found here <a href="http://jmespath.org/specification.html#wildcard-expressions">http://jmespath.org/specification.html#wildcard-expressions</a></p>
<pre><code>aws ec2 describe-volumes --query 'Volumes[*].{ID:VolumeId,AZ:AvailabilityZone,Size:Size}'
</code></pre>
<p><strong>Display only the first volume from the list of volumes</strong> returned by the describe-volumes command</p>
<pre><code>aws ec2 describe-volumes --query 'Volumes[0]'
</code></pre>
<p><strong>To filter results by the value of a specific field, use the JMESPath “?” operator.</strong> The following example query outputs only volumes in the us-west-2a<br>
Availability Zone; When specifying a literal value such as<br>
“us-west-2” above in a JMESPath query expression, you must surround<br>
the value in backticks (<code></code>) for it to be read properly</p>
<pre><code>aws ec2 describe-volumes \
    --query 'Volumes[?AvailabilityZone==`us-west-2a`]'
</code></pre>
<p><strong>List Volumes that that are attached and within a specific Availability Zone.</strong> The --query parameter further limits the output to only those volumes with a Size value that is larger than 50, and shows only the specified fields with user-defined names.</p>
<pre><code> aws ec2 describe-volumes \
    --filters "Name=availability-zone,Values=us-west-2a" "Name=status,Values=attached" \
    --query 'Volumes[?Size &gt; `50`].{Id:VolumeId,Size:Size,Type:VolumeType}'
</code></pre>
<p><strong>Display number of available volumes that are more than 1000 IOPS</strong>, uses ‘length’ to count how many volumes are in the list of attached volumes of i-xxxxxx.</p>
<pre><code>aws ec2 describe-volumes \
--filters "Name=status,Values=available" \
--query 'length(Volumes[?Iops &gt; `1000`])'
</code></pre>
<p><strong>List all snapshots that were created after a specifed date</strong></p>
<pre><code>aws ec2 describe-snapshots --owner self \
--output json \
--query 'Snapshots[?StartTime&gt;=`2018-02-07`].{Id:SnapshotId,VId:VolumeId,Size:VolumeSize}' \
</code></pre>
<p><strong>List the five most recent Amazon Machine Images (AMIs), sorted from most recent to oldest</strong></p>
<pre><code>aws ec2 describe-images \
--owners self \
--query 'reverse(sort_by(Images,&amp;CreationDate))[:5].{id:ImageId,date:CreationDate}'
</code></pre>
<p><strong>List InstanceId for unhealthy instances in a specfic auto-scaling group</strong></p>
<pre><code>aws autoscaling describe-auto-scaling-groups \ --auto-scaling-group-name `My-AutoScaling-Group-Name` \ --output text \ --query 'AutoScalingGroups[*].Instances[?HealthStatus==`Unhealthy`].InstanceId'
</code></pre>
<h2 id="efficiently-and-quickly-add-value-to-your-org-today-by-utilizing-aws-cli-querying-functionality">Efficiently and Quickly Add Value to Your Org Today by Utilizing AWS-CLI Querying Functionality</h2>
<h3 id="cloudwatch-metric-lookup-with-formatted-output-to-csv">CloudWatch Metric Lookup with Formatted Output to CSV</h3>
<h5 id="influences-and-credited-sources">Influences and Credited Sources</h5>
<p><a href="https://github.com/mikeoscarson/aswadmin">https://github.com/mikeoscarson/aswadmin</a><br>
<a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instancedata-data-retrieval.html</a></p>
<h3 id="overview">Overview</h3>
<p>This solution’s deliverable consists of a shell script that directly queries available instances, as well as the volumes that are attached to those instances, and iterates through the resulting list while executing <code>aws cloudwatch get-metric-statistics</code> commands to output a CSV file of any time series of metrics available to your IAM permissions.</p>
<h5 id="a-sample-of-the-potential-commands-that-can-be-used-with-this-solution">A sample of the potential commands that can be used with this solution</h5>
<pre><code>#CWAgent Metrics

INSTANCE_TYPE=$(aws ec2 describe-instances --filters Name=instance-id,Values=${INSTANCE} --query 'Reservations[*].Instances[*]'.[InstanceType] --profile PIEE-Test --output text)

aws cloudwatch get-metric-statistics --metric-name cpu_usage_active			  --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace CWAgent --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE},Name=InstanceType,Value=${INSTANCE_TYPE} --profile ${PROFILE_STAGE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "cpu_usage_active", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name mem_used_percent			  --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace CWAgent --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE},Name=InstanceType,Value=${INSTANCE_TYPE} --profile ${PROFILE_STAGE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "mem_used_percent", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'

#EC2 Metrics

aws cloudwatch get-metric-statistics --metric-name CPUCreditBalance           --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "CPUCreditBalance", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name CPUCreditUsage             --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile  ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "CPUCreditUsage", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name CPUSurplusCreditBalance    --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "CPUSurplusCreditBalance", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name CPUSurplusCreditsCharged   --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "CPUSurplusCreditsCharged", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name CPUUtilization             --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "CPUUtilization", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name DiskReadBytes              --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "DiskReadBytes", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name DiskReadOps                --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "DiskReadOps", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name DiskWriteBytes             --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "DiskReadOps", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name DiskWriteOps               --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "DiskWriteOps", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'
aws cloudwatch get-metric-statistics --metric-name NetworkIn                  --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EC2 --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} --profile ${PROFILE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "NetworkIn", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}'

#EBS Volume Metrics

aws cloudwatch get-metric-statistics --metric-name VolumeIdleTime --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeIdleTime", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeQueueLength --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeQueueLength", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeReadBytes --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeReadBytes", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeReadOps --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeReadOps", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeTotalReadTime --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeTotalReadTime", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeTotalWriteTime --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeTotalWriteTime", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeWriteBytes --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeWriteBytes", "'$VOLUME'", $2, $3}'
aws cloudwatch get-metric-statistics --metric-name VolumeWriteOps --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "VolumeWriteOps", "'$VOLUME'", $2, $3}'
</code></pre>
<p>These AWS-CLI commands listed above give an idea about the possibility and scope of how not only metrics can be collected, but their output can also be properly formatted and then advanced on to further processing.</p>
<p><strong>NOTE:</strong> If your use-case involves data visualization and your using Excel, it’s feasible, but any design should seek to minimize the size of data and the complexity of Excel operations; the program crashing and the subsequent data loss is inevitable.</p>
<p>Full Credit Attributed to <a href="https://raw.githubusercontent.com/mikeoscarson/aswadmin/master/cloudwatchmetrics/get_ec2_metrics.sh">https://raw.githubusercontent.com/mikeoscarson/aswadmin/master/cloudwatchmetrics/get_ec2_metrics.sh</a> for his work in collecting the metrics and the resulting output. I’ve modified and changed the process for my own use-case, which, while still a work in-progress, calls for the need to associate instances with attached volumes and individual EBS metric stats. See a snippet below:</p>
<pre><code>echo "Metric    InstanceID      Average Maximum Minimum SampleCount     Sum     YYYY-MM-DDTHH:MM:SSZ"

for INSTANCE in ${INSTANCE_LIST} ; do
    INSTANCE_TYPE=$(aws ec2 describe-instances --filters Name=instance-id,Values=${INSTANCE} --query 'Reservations[*].Instances[*]'.[InstanceType] --profile ${PROFILE_STAGE} --output text)
    #echo ${INSTANCE_TYPE}
    aws cloudwatch get-metric-statistics --metric-name cpu_usage_active --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace CWAgent --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} Name=InstanceType,Value=${INSTANCE_TYPE} --profile ${PROFILE_STAGE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "cpu_usage_active", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}' &gt;&gt; instance_metrics.csv
    aws cloudwatch get-metric-statistics --metric-name mem_used_percent --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace CWAgent --statistics ${STATISTICS} --dimensions Name=InstanceId,Value=${INSTANCE} Name=InstanceType,Value=${INSTANCE_TYPE} --profile ${PROFILE_STAGE} --output text | sort +2 -3|awk '{if ($2 &gt; 0) print "mem_used_percent", "'$INSTANCE'", $2, $3, $4, $5, $6, $7}' &gt;&gt; instance_metrics.csv

    VOLUME_LIST=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values=${INSTANCE} --query 'Volumes[].VolumeId[]' --profile${PROFILE_STAGE} --output json|awk -F\" '{print $2}')
    for VOLUME in ${VOLUME_LIST} ; do
            aws cloudwatch get-metric-statistics --metric-name VolumeReadOps --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD} --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "'$INSTANCE'", "VolumeReadOps", "'$VOLUME'", $2, $3}' &gt;&gt; volume_metrics.csv
            aws cloudwatch get-metric-statistics --metric-name VolumeWriteOps --start-time ${START}  --end-time  ${STOP}  --period  ${PERIOD}  --namespace AWS/EBS --statistics Sum --dimensions Name=VolumeId,Value=${VOLUME} --profile ${PROFILE_STAGE} --output text |sort +2 -3|awk '{print "'$INSTANCE'", "VolumeWriteOps", "'$VOLUME'", $2, $3}' &gt;&gt; volume_metrics.csv
    done 
done
</code></pre>
<p>Check out the above source repo for more scripts (they’re generally split up by AWS Service) to run through the Python CLI interface.</p>
<h4 id="execute-the-script-to-collect-and-store-metrics">Execute the Script to Collect and Store Metrics</h4>
<h6 id="startup-command-for-original-source-script">startup command for original source script:</h6>
<h6 id="bash--.get_ec2_metrics.sh-05282020-05292020--pathtoexport_file.csv">bash  ./get_ec2_metrics.sh 05/28/2020 05/29/2020 &gt; /path/to/export_file.csv</h6>
<p>That should do it! You now have an output that displays your metric collection data as follows</p>
<pre><code>  Metric	InstanceID	Average	Maximum	Minimum	SampleCount	Sum	YYYY-MM-DDTHH:MM:SSZ
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T00:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T01:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T02:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T03:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T04:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T05:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T06:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T07:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T08:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T09:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T10:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T11:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T12:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T13:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T14:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T15:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T16:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T17:00:00Z
CPUCreditBalance i-5d0945a4 576.0 576.0 576.0 12.0 6912.0 2019-07-10T18:00:00Z
</code></pre>
<p><strong>If you know of an efficient way to parse the different metric outputs into a consolidated document, please reach out so we can offer a more complete solution, as I’m still working on mine</strong></p>
<h3 id="notes-showing-how-select-metrics-are-calculated-using-pre-defined-formulas">Notes showing how select metrics are calculated using pre-defined formulas</h3>
<pre><code>    Read Bandwidth (KiB/s)

Sum(VolumeReadBytes) / Period / 1024
Write Bandwidth (KiB/s)

Sum(VolumeWriteBytes) / Period / 1024
Read Throughput (IOPS)

Sum(VolumeReadOps) / Period
Write Throughput (IOPS)

Sum(VolumeWriteOps) / Period
Avg Queue Length (Operations)

Avg(VolumeQueueLength)
% Time Spent Idle

Sum(VolumeIdleTime) / Period × 100
Avg Read Size (KiB/Operation)

Avg(VolumeReadBytes) / 1024

For Nitro-based instances, the following formula derives Average Read Size using CloudWatch Metric Math:

(Sum(VolumeReadBytes) / Sum(VolumeReadOps)) / 1024

The VolumeReadBytes and VolumeReadOps metrics are available in the EBS CloudWatch console.

Avg Write Size (KiB/Operation)

Avg(VolumeWriteBytes) / 1024

For Nitro-based instances, the following formula derives Average Write Size using CloudWatch Metric Math:

(Sum(VolumeWriteBytes) / Sum(VolumeWriteOps)) / 1024

The VolumeWriteBytes and VolumeWriteOps metrics are available in the EBS CloudWatch console.

Avg Read Latency (ms/Operation)

Avg(VolumeTotalReadTime) × 1000

For Nitro-based instances, the following formula derives Average Read Latency using CloudWatch Metric Math:

(Sum(VolumeTotalReadTime) / Sum(VolumeReadOps)) × 1000

The VolumeTotalReadTime and VolumeReadOps metrics are available in the EBS CloudWatch console.

Avg Write Latency (ms/Operation)

Avg(VolumeTotalWriteTime) × 1000

For Nitro-based instances, the following formula derives Average Write Latency using CloudWatch Metric Math:

(Sum(VolumeTotalWriteTime) / Sum(VolumeWriteOps)) * 1000

The VolumeTotalWriteTime and VolumeWriteOps metrics are available in the EBS CloudWatch console.
</code></pre>
<h3 id="retrieving-ec2-metadata-while-on-instance">Retrieving EC2 metadata while on Instance</h3>
<p>You can also download the Instance Metadata Query tool, which allows you to query the instance metadata using Instance Metadata Service Version 1 without having to enter the full URI or category names.</p>
<p>Instance Metadata Query Tool URL:<br>
<a href="https://aws.amazon.com/code/ec2-instance-metadata-query-tool/">https://aws.amazon.com/code/ec2-instance-metadata-query-tool/</a></p>
<p>While the above tool is an official AWS solution, a community tool with a Python wrapper is a solid choice to use as well. It can be installed as a Python module, the source code can be found here:<br>
<a href="https://github.com/adamchainz/ec2-metadata">https://github.com/adamchainz/ec2-metadata</a></p>
<p>Example of Usage</p>
<blockquote>
<blockquote>
<blockquote>
<p>from ec2_metadata import ec2_metadata<br>
print(ec2_metadata.region)<br>
us-east-1</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>print(ec2_metadata.instance_id)<br>
i-123456</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>This is still a work in-progress, but reflects the ability to use a Lambda with Bash and AWSCLI capabilities to execute the AWS SSM RunShellScript directly on instances and collect their metadata…feel free to update and refine these commands</strong></p>
<pre><code>#INSTANCE_ENVIRONMENT_TYPE=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[].Instances[].Tags[?Key==`environment_type`].Value[] --output text')
#INSTANCE_APPLICATION=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[].Instances[].Tags[?Key==`application`].Value[]' --output text)
#INSTANCE_DISTRIBUTION=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[].Instances[].Tags[?Key==`distribution`].Value[]' --output text])



#get_account_id='INSTANCE_ACCOUNT_ID=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document); echo $INSTANCE_ACCOUNT_ID'

#INSTANCE_ACCOUNT_ID=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | python -c "import sys, json; print(json.load(sys.stdin))['accountId']" )
#INSTANCE_ACCOUNT_ID=$("| python -c "import sys, json; print(json.load(sys.stdin))['accountId']")



#INSTANCE_REGION=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | python -c "import sys, json; print(json.load(sys.stdin))['region']")
#INSTANCE_VPC_ID=$(aws ec2 describe-instances --instance-id i-6fedd222 --query 'Reservations[0].Instances[0].NetworkInterfaces[0].VpcId' --output text)
#INSTANCE_AVAILABILITY_ZONE=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document/availabilityZone)
#INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
#INSTANCE_NAME=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[].Instances[].Tags[?Key==`Name`].Value[]' --output text)
#INSTANCE_TYPE=$(curl -s http://169.254.169.254/latest/meta-data/instance-type)
#INSTANCE_PRIVATE_IP=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document/privateIp)
#observed values using free for ram &amp; aws api to retrieve cpu cores on instance 
#total ram on instance	-- use -m for MB, -g for GB after -t (https://stackoverflow.com/questions/2441046/how-to-get-the-total-physical-memory-in-bash-to-assign-it-to-a-variable)
#TOTAL_RAM_IN_GB=$(free -t -g | grep -oP '\d+' | sed '10!d')
#INSTANCE_CPU_CORES=$(echo $INSTANCE_INFO | python -c "import sys, json; print(json.load(sys.stdin)['Reservations'][0]['Instances'][0]['CpuOptions'][0]['CoreCount'])" )
#instance type default cpu and ram 
#TYPE_INFO=$(aws ec2 describe-instance-types --instance-types $INSTANCE_TYPE --region $REGION)
#MEMORYINFO_SIZE_IN_MB=$(echo $TYPE_INFO | python -c "import sys, json; print(json.load(sys.stdin)['InstanceTypes'][0]['MemoryInfo']['SizeInMiB'])" )
#INSTANCE_TYPE_VCPUS=$(echo $TYPE_INFO | python -c "import sys, json; print(json.load(sys.stdin)['InstanceTypes'][0]['VCpuInfo']['DefaultVCpus'])" )
#instance ebs info 
#INSTANCE_EBS_SIZE_IN_GB=$(aws ec2 describe-volumes --region $REGION --filters Name=attachment.instance-id,Values=$INSTANCE_ID --query 'sum(Volumes[].Size)' --output text)
#INSTANCE_EBS_TOTAL_IOPS=$(aws ec2 describe-volumes --region $REGION --filters Name=attachment.instance-id,Values=$INSTANCE_ID --query 'sum(Volumes[].Iops)' --output text)
</code></pre>
<p>Countless more variations and options are possible for extracting metrics and instance metadata. Post your idea for an end-to-end solution, and I’ll do my best to develop it. I’ll continue to update this page and include the more granular details of manipulating output with the AWS-CLI.</p>
<p>Thanks for contributing and supporting the Encyclopedia.</p>

